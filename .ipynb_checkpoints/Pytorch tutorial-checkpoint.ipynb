{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c16491",
   "metadata": {},
   "source": [
    "# Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31a51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78eb8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e91e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9220, 0.9072, 0.1890])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79efddc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff407a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.ones(2,2,3,dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "099b8b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1],\n",
       "         [1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c20deede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e2b688c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de399af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([2.5,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88806ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 0.1000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91688432",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(2,2)\n",
    "y=torch.rand(2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a43ba6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0735, 0.0612],\n",
       "        [0.9774, 1.7964]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9f710ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0735, 0.0612],\n",
       "        [0.9774, 1.7964]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a2bff77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2193, 0.0224],\n",
       "        [0.5289, 0.8690]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ogni funzione che ha un underscore do an in place operation qundi modifica la variabile a cui\n",
    "#è applicata\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0af443af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0735, 0.0612],\n",
       "        [0.9774, 1.7964]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26f28a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0735, 0.0612],\n",
       "        [0.9774, 1.7964]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74fb23e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9170, 0.0024],\n",
       "        [0.4384, 1.6659]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mul_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71e72ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9170, 0.0024],\n",
       "        [0.4384, 1.6659]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1df5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "808367f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12dcc188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30598074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50db2203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f83618b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e53dae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b # anche b è cambiato perche tutti e due puntano alla stessa memory location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "536953cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b1a096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0364148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cf2edc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5b4ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3acade2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5da1a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b # anche b è cambiato perche tutti e due puntano alla stessa memory location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "    x=torch.ones(5,device=device)\n",
    "    y=torch.ones(5)\n",
    "    y=y.to(device)\n",
    "    z=x+y #il tensore in questo modo si troverà sulla gpu e non è possibile trasformarlo direttamente\n",
    "        # in un numpy array perchè numpy can only handle cpu tensor\n",
    "    z=z.to('cpu')\n",
    "    z=z.numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83251373",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(3,requires_grad=True)\n",
    "# vuol dire che bisognerà calcolare i gradienti per questo tensore nell'optimization steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543c82d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5115, -0.7729,  0.1698], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02a8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c631ffff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5115, 1.2271, 2.1698], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1a4fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=y*y*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3c710b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12.6148,  3.0113,  9.4165], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6349d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58558a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.3475, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3642d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward() #dz/dx\n",
    "\n",
    "#se la variabile su cui chiamiamo backward non è uno scalare allora dobbiamo passare\n",
    "#in input un vettore della stessa dimensione\n",
    "#v=torch.tensor([0.1,1,0.001],dtype=torch.float32)\n",
    "#z.backward(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44cb7518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.3475, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6380ece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3486, 1.6361, 2.8931])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per evitare che vengano calcolati i gradienti \n",
    "#tacking the history of gradients in the computational graph\n",
    "\n",
    "#x.requires_grad_(False) quando l underscore sta alla fine vuol dire che la funzione modifica\n",
    "#                        la variabile in place\n",
    "#x.detach()\n",
    "#with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a697d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5115, -0.7729,  0.1698], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76a88509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5115, -0.7729,  0.1698])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c050d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2651a6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7646, -0.8215, -0.2554])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acf443f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y=x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be6f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7646, 1.1785, 1.7446])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47c9165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# ogni volta che viene chiamata la funzione backward i gradienti vengono sommati, accumulati \n",
    "# nella variabile x.grad, per evitare questo bisogna azzerarli ogni volta\n",
    "# x.grad.zero_()\n",
    "\n",
    "weights=torch.ones(4,requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output=(weights*3).sum()\n",
    "    \n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11d79228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.0)\n",
    "y=torch.tensor(2.0)\n",
    "w=torch.tensor(1.0,requires_grad=True)\n",
    "\n",
    "#forward pass\n",
    "y_hat=w*x\n",
    "loss=(y_hat-y)**2\n",
    "print(loss)\n",
    "#backward pass\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b90331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da03544",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "378bd383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) = 0.000\n",
      "epoch 1: w= 1.200,loss=30.00000000\n",
      "epoch 2: w= 1.680,loss=4.79999924\n",
      "epoch 3: w= 1.872,loss=0.76800019\n",
      "epoch 4: w= 1.949,loss=0.12288000\n",
      "epoch 5: w= 1.980,loss=0.01966083\n",
      "epoch 6: w= 1.992,loss=0.00314570\n",
      "epoch 7: w= 1.997,loss=0.00050332\n",
      "epoch 8: w= 1.999,loss=0.00008053\n",
      "epoch 9: w= 1.999,loss=0.00001288\n",
      "epoch 10: w= 2.000,loss=0.00000206\n",
      "Prediction after training : f(5) = 9.999\n"
     ]
    }
   ],
   "source": [
    "X=np.array([1,2,3,4],dtype=np.float32)\n",
    "Y=np.array([2,4,6,8],dtype=np.float32)\n",
    "\n",
    "w=0\n",
    "\n",
    "def forward(x):\n",
    "    return w*x  #dato che w non viene modificata allora è possibile dichiararla fuori\n",
    "                #w è una variabile globale \n",
    "                #se la si vuole modificate all'interno della funzione allora sarà ritornato un errore\n",
    "                #per modificarla bisogna bisogna specificare che ci stiamo riferendo alla \n",
    "                # variabile globale w con global w\n",
    "                \n",
    "\n",
    "def loss(y,y_predicted):\n",
    "    return((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE= 1/N *(w*x-y)**2\n",
    "# dJ/dx = 1/N *2x * (w*x-y)\n",
    "\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x,y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before training : f(5) = {forward(5):.3f}')\n",
    "\n",
    "#training\n",
    "lr=0.01\n",
    "n_iters=10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    #prediction = forward pass\n",
    "    y_pred=forward(X)\n",
    "    \n",
    "    #loss\n",
    "    l=loss(Y,y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    dw=gradient(X,Y,y_pred)\n",
    "    \n",
    "    #update weights\n",
    "    w-=lr*dw\n",
    "    \n",
    "    if epoch % 1==0:\n",
    "        print(f'epoch {epoch+1}: w= {w:.3f},loss={l:.8f}')\n",
    "        \n",
    "print(f'Prediction after training : f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2801e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86225292",
   "metadata": {},
   "source": [
    "# Gradient descent with autograd and backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b66c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) = 0.000\n",
      "epoch 1: w= 0.300,loss=30.00000000\n",
      "epoch 2: w= 0.555,loss=21.67499924\n",
      "epoch 3: w= 0.772,loss=15.66018772\n",
      "epoch 4: w= 0.956,loss=11.31448650\n",
      "epoch 5: w= 1.113,loss=8.17471695\n",
      "epoch 6: w= 1.246,loss=5.90623236\n",
      "epoch 7: w= 1.359,loss=4.26725292\n",
      "epoch 8: w= 1.455,loss=3.08308983\n",
      "epoch 9: w= 1.537,loss=2.22753215\n",
      "epoch 10: w= 1.606,loss=1.60939169\n",
      "Prediction after training : f(5) = 8.031\n"
     ]
    }
   ],
   "source": [
    "X=torch.tensor([1,2,3,4])\n",
    "Y=torch.tensor([2,4,6,8])\n",
    "\n",
    "w=torch.tensor(0.0,requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x  #dato che w non viene modificata allora è possibile dichiararla fuori\n",
    "                #w è una variabile globale \n",
    "                #se la si vuole modificate all'interno della funzione allora sarà ritornato un errore\n",
    "                #per modificarla bisogna bisogna specificare che ci stiamo riferendo alla \n",
    "                # variabile globale w con global w\n",
    "                \n",
    "\n",
    "def loss(y,y_predicted):\n",
    "    return((y_predicted-y)**2).mean()\n",
    "\n",
    "\n",
    "\n",
    "print(f'Prediction before training : f(5) = {forward(5):.3f}')\n",
    "\n",
    "#training\n",
    "lr=0.01\n",
    "n_iters=10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    #prediction = forward pass\n",
    "    y_pred=forward(X)\n",
    "    \n",
    "    #loss\n",
    "    l=loss(Y,y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    l.backward()\n",
    "    \n",
    "    #update weights\n",
    "    #PyTorch doesn’t allow in-place operations on leaf variables\n",
    "    #that have requires_grad=True (such as parameters of your model) \n",
    "    #because the developers could not decide how such an operation should behave\n",
    "    with torch.no_grad():\n",
    "        w-=lr*w.grad\n",
    "    \n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 1==0:\n",
    "        print(f'epoch {epoch+1}: w= {w:.3f},loss={l:.8f}')\n",
    "        \n",
    "print(f'Prediction after training : f(5) = {forward(5):.3f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee2a7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8d71c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "403c7bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e469940",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([2,3,4],requires_grad=True,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31e0608b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 4.], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "600c415d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13668/585000414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "x+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48abdf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b90da53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6.], requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15e849",
   "metadata": {},
   "source": [
    "## Training pipeline\n",
    "\n",
    "* design model (input,output size,forward pass)\n",
    "* construct loss and optimizer\n",
    "* training loop:\n",
    "     *  forward pass: compute prediction\n",
    "     * backward pass : gradients\n",
    "     * update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a040c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "Y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "\n",
    "X_test=torch.tensor([5],dtype=torch.float32)\n",
    "\n",
    "n_samples,n_features=X.shape\n",
    "\n",
    "input_size=n_features\n",
    "output_size=n_features\n",
    "\n",
    "#model= nn.Linear(input_size,output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        #super(LinearRegression,self).__init__()\n",
    "        super().__init__()\n",
    "        #define layers\n",
    "        self.lin=nn.Linear(input_dim,output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model= LinearRegression(input_size,output_size)\n",
    "\n",
    "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "#training\n",
    "lr=0.01\n",
    "n_iters=100\n",
    "\n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    #prediction = forward pass\n",
    "    y_pred=model(X)\n",
    "    \n",
    "    #loss\n",
    "    l=loss(Y,y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    l.backward()\n",
    "    \n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10==0:\n",
    "        [w,b]=model.parameters()\n",
    "        print(f'epoch {epoch+1}: w= {w[0][0]:.3f},loss={l:.8f}')\n",
    "        \n",
    "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2842267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa7f26c2",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6466112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 , loss 5828.7080\n",
      "epoch 11 , loss 4317.2529\n",
      "epoch 21 , loss 3224.1060\n",
      "epoch 31 , loss 2432.6299\n",
      "epoch 41 , loss 1858.9894\n",
      "epoch 51 , loss 1442.8387\n",
      "epoch 61 , loss 1140.6775\n",
      "epoch 71 , loss 921.1057\n",
      "epoch 81 , loss 761.4321\n",
      "epoch 91 , loss 645.2377\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0 prepare data\n",
    "\n",
    "x_numpy,y_numpy=datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1)\n",
    "\n",
    "x=torch.from_numpy(x_numpy.astype(np.float32))\n",
    "y=torch.from_numpy(y_numpy.astype(np.float32))\n",
    "\n",
    "y=y.view(y.shape[0],1)\n",
    "\n",
    "n_samples,n_features=x.shape\n",
    "\n",
    "# 1 model\n",
    "\n",
    "input_size=n_features\n",
    "output_size=1\n",
    "\n",
    "model= nn.Linear(input_size,output_size)\n",
    "\n",
    "# 2 loss and optimizer\n",
    "lr=0.01\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "# 3 training loop\n",
    "num_epoch=100\n",
    "for epoch in range(num_epoch):\n",
    "    y_pred=model(x)\n",
    "    loss=criterion(y_pred,y)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 ==0:\n",
    "        \n",
    "        print(f'epoch {epoch+1} , loss {loss.item():.4f}')\n",
    "\n",
    "#plot\n",
    "\n",
    "predicted=model(x).detach().numpy()\n",
    "plt.plot(x_numpy,y_numpy,'ro')\n",
    "plt.plot(x_numpy,predicted,'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81d75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f55051f5",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6763e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 , loss 0.6697\n",
      "epoch 11 , loss 0.5162\n",
      "epoch 21 , loss 0.4278\n",
      "epoch 31 , loss 0.3716\n",
      "epoch 41 , loss 0.3327\n",
      "epoch 51 , loss 0.3040\n",
      "epoch 61 , loss 0.2818\n",
      "epoch 71 , loss 0.2641\n",
      "epoch 81 , loss 0.2496\n",
      "epoch 91 , loss 0.2374\n",
      "accuracy = 0.9298\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bc=datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "x,y=bc.data, bc.target\n",
    "\n",
    "n_samples,n_features=x.shape\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1234)\n",
    "\n",
    "# scale\n",
    "\n",
    "sc=StandardScaler()               #in modo che le features abbiano media zero e vaianza 1\n",
    "X_train=sc.fit_transform(X_train) # calcola ma media e la std e le usa per standardizzare il train\n",
    "X_test=sc.transform(X_test)     # usa la media e la std trovata nel train per standardizzare il test\n",
    "\n",
    "\n",
    "X_train=torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test=torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train=torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test=torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train=y_train.view(y_train.shape[0],1)\n",
    "y_test=y_test.view(y_test.shape[0],1)\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_input_features):\n",
    "        super(LogisticRegression,self).__init__()\n",
    "        self.linear=nn.Linear(n_input_features,1)\n",
    "    def forward(self,x):\n",
    "        y_pred=torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "model=LogisticRegression(n_features)\n",
    "\n",
    "lr=0.01\n",
    "criterion= nn.BCELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    #forward pass and loss\n",
    "    y_pred=model(X_train)\n",
    "    loss=criterion(y_pred,y_train)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    #zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if e%10 ==0:\n",
    "        print(f'epoch {e+1} , loss {loss.item():.4f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    y_pred=model(X_test)\n",
    "    y_pred_class=y_pred.round()\n",
    "    \n",
    "    acc=y_pred_class.eq(y_test).sum()/ float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63a13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08e0834b",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader Batch training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e5db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02e7a026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
      "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        #data loader\n",
    "        xy=np.loadtxt('./wine.csv',delimiter=',',dtype=np.float32,skiprows=1)\n",
    "        self.x=torch.from_numpy(xy[:,1:])\n",
    "        self.y=torch.from_numpy(xy[:,[0]])  #in modo che lo shape sia n_samples,1\n",
    "        self.n_samples=xy.shape[0]\n",
    "        \n",
    "        # es\n",
    "        # a=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "        # a[:,[0]]\n",
    "        # array([[1],\n",
    "        #       [4],\n",
    "        #       [7]])\n",
    "        \n",
    "          \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        \n",
    "# create dataset\n",
    "dataset=WineDataset()\n",
    "\n",
    "first_data=dataset[0]\n",
    "features, label=first_data\n",
    "#print(features, labels)\n",
    "\n",
    "# Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "dataloader=DataLoader(dataset=dataset,batch_size=4,shuffle=True)\n",
    "\n",
    "# convert to an iterator and look at one random sample\n",
    "dataiter=iter(dataloader)\n",
    "data=dataiter.next()\n",
    "features,labels=data\n",
    "#print(features, labels)\n",
    "\n",
    "\n",
    "#training loop\n",
    "num_epochs=2\n",
    "total_samples=len(dataset)\n",
    "n_iterations=math.ceil(total_samples/4)\n",
    "\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    for i, (inputs,labels) in enumerate(dataloader):\n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {e+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02b6c3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e75542246654f08973d54526c03fbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab752964aebd44c9881bfbbdd6062d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cabb753c9e4ea9b9c554971320e7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ece327bc7cc4aa68ff6edc3b0a0ebe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "torch.Size([3, 1, 28, 28]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# some famous datasets are available in torchvision.datasets\n",
    "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=torchvision.transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=3, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# look at one random sample\n",
    "dataiter = iter(train_loader)\n",
    "data = dataiter.next()\n",
    "inputs, targets = data\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7403cc7",
   "metadata": {},
   "source": [
    "# Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c85c03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,transform=None):\n",
    "        #data loader\n",
    "        xy=np.loadtxt('./wine.csv',delimiter=',',dtype=np.float32,skiprows=1)\n",
    "        \n",
    "        self.x=xy[:,1:]\n",
    "        self.y=xy[:,[0]] \n",
    "        self.n_samples=xy.shape[0]\n",
    "        \n",
    "        self.transform=transform\n",
    "        \n",
    "        # es\n",
    "        # a=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "        # a[:,[0]]\n",
    "        # array([[1],\n",
    "        #       [4],\n",
    "        #       [7]])\n",
    "        \n",
    "          \n",
    "    def __getitem__(self,index):\n",
    "        sample= self.x[index],self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample=self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "class ToTensor:\n",
    "    \n",
    "    def __call__(self,sample):\n",
    "        inputs,targets =sample\n",
    "        return torch.from_numpy(inputs),torch.from_numpy(targets)\n",
    "\n",
    "    \n",
    "class MulTransform:\n",
    "    \n",
    "    def __init__(self,factor):\n",
    "        self.factor=factor\n",
    "        \n",
    "    def __call__(self,sample):\n",
    "        inputs,targets =sample\n",
    "        inputs*=self.factor\n",
    "        return inputs,targets\n",
    "\n",
    "#dataset=WineDataset(transform=ToTensor())\n",
    "dataset=WineDataset(transform=None)\n",
    "\n",
    "first_data=dataset[0]\n",
    "features,labels=first_data\n",
    "print(features)\n",
    "print(type(features),type(labels))\n",
    "\n",
    "\n",
    "composed=torchvision.transforms.Compose([ToTensor(),MulTransform(2)])\n",
    "dataset=WineDataset(transform=composed)\n",
    "first_data=dataset[0]\n",
    "features,labels=first_data\n",
    "print(features)\n",
    "print(type(features),type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13100e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
